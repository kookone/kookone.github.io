---
layout: post
title: Netty高性能实战
category: Blog
tags: [Netty]
---

> ## Netty是什么

Netty是一个高性能、异步事件驱动的NIO框架，它提供了对TCP、UDP和文件传输的支持，作为一个异步NIO框架，Netty的所有IO操作都是异步非阻塞的，通过Future-Listener机制，用户可以方便的主动获取或者通过通知机制获得IO操作结果。

作为当前最流行的NIO框架，Netty在互联网领域、大数据分布式计算领域、游戏行业、通信行业等获得了广泛的应用，一些业界著名的开源组件也基于Netty的NIO框架构建。

> ## 为什么选择Netty

Netty是业界最流行的NIO框架之一，它的健壮性、功能、性能、可定制性和可扩展性在同类框架中都是首屈一指的，它已经得到成百上千的商用项目验证，例如Hadoop的RPC框架avro使用Netty作为底层通信框架；很多其他业界主流的RPC框架，也使用Netty来构建高性能的异步通信能力。

通过对Netty的分析，我们将它的优点总结如下:

- API使用简单，开发门槛低

- 功能强大，预置了多种编解码功能，支持多种主流协议

- 定制能力强，可以通过ChannelHandler对通信框架进行灵活地扩展

- 性能高，通过与其他业界主流的NIO框架对比，Netty的综合性能最优

- 成熟、稳定，Netty修复了已经发现的所有JDK NIO BUG，业务开发人员不需要再为NIO的BUG而烦恼

- 社区活跃，版本迭代周期短，发现的BUG可以被及时修复，同时，更多的新功能会加入

- 经历了大规模的商业应用考验，质量得到验证。在互联网、大数据、网络游戏、企业应用、电信软件等众多行业得到成功商用，证明了它已经完全能够满足不同行业的商业应用了

> ## Netty工作原理分析

server端工作原理如下图：

![NettyServer整体架构图](http://onekook.com/bower_components/extend/images/netty-server.png)

server端启动时绑定本地某个端口，将自己NioServerSocketChannel注册到某个boss NioEventLoop的selector上。  
server端包含1个boss NioEventLoopGroup和1个worker NioEventLoopGroup，NioEventLoopGroup相当于1个事件循环组，这个组里包含多个事件循环NioEventLoop，每个NioEventLoop包含1个selector和1个事件循环线程。  
每个boss NioEventLoop循环执行的任务包含3步：

- 第1步：轮询accept事件；
- 第2步：处理io任务，即accept事件，与client建立连接，生成NioSocketChannel，并将NioSocketChannel注册到某个worker NioEventLoop的selector上；
- 第3步：处理任务队列中的任务，runAllTasks。任务队列中的任务包括用户调用eventloop.execute或schedule执行的任务，或者其它线程提交到该eventloop的任务。

每个worker NioEventLoop循环执行的任务包含3步：

- 第1步：轮询read、write事件；
- 第2步：处理io任务，即read、write事件，在NioSocketChannel可读、可写事件发生时进行处理；
- 第3步：处理任务队列中的任务，runAllTasks。

client端工作原理如下图：

![NettyClient整体架构图](http://onekook.com/bower_components/extend/images/netty-client.png)

client端启动时connect到server，建立NioSocketChannel，并注册到某个NioEventLoop的selector上。  
client端只包含1个NioEventLoopGroup，每个NioEventLoop循环执行的任务包含3步：

- 第1步：轮询connect、read、write事件；
- 第2步：处理io任务，即connect、read、write事件，在NioSocketChannel连接建立、可读、可写事件发生时进行处理；
- 第3步：处理非io任务，runAllTasks。

以上转载自简书：https://www.jianshu.com/p/03bb8a945b37  

> ## Netty架构分析

Netty 采用了比较典型的三层网络架构进行设计，逻辑架构图如下所示：

![Netty架构图](http://onekook.com/bower_components/extend/images/Netty%E6%9E%B6%E6%9E%84%E5%9B%BE.JPEG)

第一层

：Reactor 通信调度层，它由一系列辅助类完成，包括 Reactor 线程 NioEventLoop 以及其父类、NioSocketChannel/NioServerSocketChannel 以及其父 类、ByteBuffer 以及由其衍生出来的各种 Buffer、Unsafe 以及其衍生出的各种内 部类等。该层的主要职责就是监听网络的读写和连接操作，负责将网络层的数据 读取到内存缓冲区中，然后触发各种网络事件，例如连接创建、连接激活、读事 件、写事件等等，将这些事件触发到 PipeLine 中，由 PipeLine 充当的职责链来 进行后续的处理。

第二层

：职责链 PipeLine，它负责事件在职责链中的有序传播，同时负责动态的 编排职责链，职责链可以选择监听和处理自己关心的事件，它可以拦截处理和向 后/向前传播事件，不同的应用的 Handler 节点的功能也不同，通常情况下，往往 会开发编解码 Hanlder 用于消息的编解码，它可以将外部的协议消息转换成内部 的 POJO 对象，这样上层业务侧只需要关心处理业务逻辑即可，不需要感知底层 的协议差异和线程模型差异，实现了架构层面的分层隔离。

第三层

：业务逻辑处理层，可以分为两类：

纯粹的业务逻辑 处理，例如订单处理。

应用层协议管理，例如HTTP协议、FTP协议等。

---

#### 接下来，我从影响通信性能的三个方面（I/O模型、线程调度模型、序列化方式）来谈谈Netty的架构。

> ## I/O模型

`传统同步阻塞I/O模式`如下图所示：

![BIO](http://onekook.com/bower_components/extend/images/BIO.JPEG)

它的`弊端`有很多：

- 性能问题：一连接一线程模型导致服务端的并发接入数和系统吞吐量受到极大限制；

- 可靠性问题：由于I/O操作采用同步阻塞模式，当网络拥塞或者通信对端处理缓慢会导致I/O线程被挂住，阻塞时间无法预测；

- 可维护性问题：I/O线程数无法有效控制、资源无法有效共享（多线程并发问题），系统可维护性差；

几种I/O模型的功能和特性对比：

![IO模式对比](http://onekook.com/bower_components/extend/images/compare-IO.JPEG)

Netty的I/O模型基于非阻塞I/O实现，底层依赖的是JDK NIO框架的Selector，Selector提供选择已经就绪的任务的能力。

简单来讲，Selector会不断地轮询注册在其上的Channel，如果某个Channel上面有新的TCP连接接入、读和写事件，这个Channel就处于就绪状态，会被Selector轮询出来，然后通过SelectionKey可以获取就绪Channel的集合，进行后续的I/O操作。

一个多路复用器Selector可以同时轮询多个Channel，由于JDK1.5_update10版本（+）使用了epoll()代替传统的select实现，所以它并没有最大连接句柄1024/2048的限制。这也就意味着只需要一个线程负责Selector的轮询，就可以接入成千上万的客户端，这确实是个非常巨大的技术进步。

使用非阻塞I/O模型之后，Netty解决了传统同步阻塞I/O带来的性能、吞吐量和可靠性问题。
